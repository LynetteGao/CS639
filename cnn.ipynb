{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "639.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4k7t5Y2v4Mz"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JYBPtYWwUcq"
      },
      "source": [
        "!ls '/content/drive/MyDrive/CS 639 Project/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZGYLj3M09TG"
      },
      "source": [
        "root = '/content/drive/MyDrive/CS 639 Project/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "magbAo0xwoRI"
      },
      "source": [
        "# load label of each image\n",
        "def label_loader(label_file):\n",
        "    train_img_label_pair = {}\n",
        "    test_img_label_pair ={}\n",
        "    with open(label_file) as all_label:\n",
        "        for label in all_label:\n",
        "            label = label.rstrip()\n",
        "            if label.startswith(\"train\"):\n",
        "                train_img_label_pair[label.split(\" \")[0][:-4]+\"_aligned.jpg\"] = int(label.split(\" \")[1])\n",
        "            if label.startswith(\"test\"):\n",
        "                test_img_label_pair[label.split(\" \")[0][:-4]+\"_aligned.jpg\"] = int(label.split(\" \")[1])\n",
        "    return train_img_label_pair, test_img_label_pair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeRLFUkP05Zc"
      },
      "source": [
        "import numpy as np\n",
        "def plot(history, log_name, num_epoch):\n",
        "    \"\"\"\n",
        "    plot accuracy and loss save to \"./imgs\"\n",
        "    :param history: tensorflow History Object\n",
        "    :param log_name: String:name of the log\n",
        "    :param num_epoch: int: number of epoches\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    if not os.path.exists(root + 'graph'):\n",
        "        print(\"First run, make dir\")\n",
        "        os.makedirs(root + 'graph')\n",
        "    plt.plot(np.linspace(1, num_epoch, num_epoch),\n",
        "             np.array(history.history[\"categorical_accuracy\"]), label='Training Accuracy', color='b')\n",
        "    plt.plot(np.linspace(1, num_epoch, num_epoch),\n",
        "             np.array(history.history[\"val_categorical_accuracy\"]), label='Test Accuracy', color='r')\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy\" + log_name + time.ctime())\n",
        "    plt.savefig(root +\"graph/Accuracy \" + log_name)\n",
        "    # plt.show()\n",
        "    plt.close()\n",
        "    plt.plot(np.linspace(1, num_epoch, num_epoch), np.array(history.history[\"loss\"]), label='Training Loss', color='b')\n",
        "    plt.plot(np.linspace(1, num_epoch, num_epoch),\n",
        "             np.array(history.history[\"val_loss\"]), label='Test Loss', color='r')\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\" + log_name + time.ctime())\n",
        "    plt.savefig(root +\"graph/Loss \" + log_name)\n",
        "    # plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XZQpExAhFkS"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "def Model():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(128, kernel_size=3, activation='relu', input_shape=(100,100,3)),\n",
        "        layers.Conv2D(128, kernel_size=3, activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(7, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adadelta(0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                 metrics=[tf.keras.metrics.categorical_accuracy])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5HQ7CsPwWF6"
      },
      "source": [
        "# create image label pair as a dictionary\n",
        "label_file = root + 'list_patition_label.txt'\n",
        "train_img_label_pair, test_img_label_pair = label_loader(label_file)\n",
        "\n",
        "# Use pickle to speed up reading data\n",
        "import pickle\n",
        "input_shape = (100, 100)\n",
        "print(\"Loading Data\")\n",
        "try:\n",
        "    train_img, train_label, test_img, test_label = pickle.load(open(root + \"processed_data_\"+str(input_shape)+\".pickle\", 'rb'))\n",
        "    print(\"Shape\", train_img.shape)\n",
        "except:\n",
        "    print(\"Error occurred when loading data\")\n",
        "\n",
        "import os\n",
        "trained_model_dir = root + \"trained_model_optimized\"\n",
        "if not os.path.exists(trained_model_dir):\n",
        "    print(\"First run, make model dir\")\n",
        "    os.makedirs(trained_model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdqnvNYMwY-E"
      },
      "source": [
        "num_epoch = 200\n",
        "batch_size = 64\n",
        "model = Model()\n",
        "\n",
        "log_name = input(\"What's the name of this run?:\")\n",
        "\n",
        "# Keras model and Tensor Board\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import time\n",
        "tb = TensorBoard(log_dir=\"logs/\" + log_name)\n",
        "chk = ModelCheckpoint(trained_model_dir+log_name+\"_chk.h5\", monitor='val_categorical_accuracy', verbose=0,\n",
        "                      save_best_only=True, save_weights_only=True, mode='max', save_freq=1)\n",
        "\n",
        "history = model.fit(train_img, train_label, epochs=num_epoch, batch_size=batch_size,\n",
        "                    validation_data=(test_img, test_label), callbacks=[tb, chk])\n",
        "\n",
        "model.summary()\n",
        "plot(history, log_name, num_epoch)\n",
        "model.save(trained_model_dir+\"/\"+log_name+\".h5\")\n",
        "loss, accuracy = model.evaluate(test_img, test_label,batch_size=32)\n",
        "print(\"test loss:\", loss)\n",
        "print(\"test accuracy:\", accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bGEkxZpvL7U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}